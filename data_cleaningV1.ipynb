{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_STATE\n",
      "FMONTH\n",
      "IDATE\n",
      "IMONTH\n",
      "IDAY\n",
      "IYEAR\n",
      "DISPCODE\n",
      "SEQNO\n",
      "_PSU\n",
      "CTELENM1\n",
      "PVTRESD1\n",
      "COLGHOUS\n",
      "STATERE1\n",
      "CELPHON1\n",
      "LADULT1\n",
      "NUMADULT\n",
      "RESPSLC1\n",
      "LANDSEX2\n",
      "LNDSXBRT\n",
      "SAFETIME\n",
      "CTELNUM1\n",
      "CELLFON5\n",
      "CADULT1\n",
      "CELLSEX2\n",
      "CELSXBRT\n",
      "PVTRESD3\n",
      "CCLGHOUS\n",
      "CSTATE1\n",
      "LANDLINE\n",
      "HHADULT\n",
      "SEXVAR\n",
      "GENHLTH\n",
      "PHYSHLTH\n",
      "MENTHLTH\n",
      "POORHLTH\n",
      "PRIMINS1\n",
      "PERSDOC3\n",
      "MEDCOST1\n",
      "CHECKUP1\n",
      "EXERANY2\n",
      "EXRACT12\n",
      "EXEROFT1\n",
      "EXERHMM1\n",
      "EXRACT22\n",
      "EXEROFT2\n",
      "EXERHMM2\n",
      "STRENGTH\n",
      "BPHIGH6\n",
      "BPMEDS1\n",
      "CHOLCHK3\n",
      "TOLDHI3\n",
      "CHOLMED3\n",
      "CVDINFR4\n",
      "CVDCRHD4\n",
      "CVDSTRK3\n",
      "ASTHMA3\n",
      "ASTHNOW\n",
      "CHCSCNC1\n",
      "CHCOCNC1\n",
      "CHCCOPD3\n",
      "ADDEPEV3\n",
      "CHCKDNY2\n",
      "HAVARTH4\n",
      "DIABETE4\n",
      "DIABAGE4\n",
      "MARITAL\n",
      "EDUCA\n",
      "RENTHOM1\n",
      "NUMHHOL4\n",
      "NUMPHON4\n",
      "CPDEMO1C\n",
      "VETERAN3\n",
      "EMPLOY1\n",
      "CHILDREN\n",
      "INCOME3\n",
      "PREGNANT\n",
      "WEIGHT2\n",
      "HEIGHT3\n",
      "DEAF\n",
      "BLIND\n",
      "DECIDE\n",
      "DIFFWALK\n",
      "DIFFDRES\n",
      "DIFFALON\n",
      "FALL12MN\n",
      "FALLINJ5\n",
      "SMOKE100\n",
      "SMOKDAY2\n",
      "USENOW3\n",
      "ECIGNOW2\n",
      "ALCDAY4\n",
      "AVEDRNK3\n",
      "DRNK3GE5\n",
      "MAXDRNKS\n",
      "FLUSHOT7\n",
      "FLSHTMY3\n",
      "PNEUVAC4\n",
      "SHINGLE2\n",
      "HIVTST7\n",
      "HIVTSTD3\n",
      "SEATBELT\n",
      "DRNKDRI2\n",
      "COVIDPO1\n",
      "COVIDSM1\n",
      "COVIDACT\n",
      "PDIABTS1\n",
      "PREDIAB2\n",
      "DIABTYPE\n",
      "INSULIN1\n",
      "CHKHEMO3\n",
      "EYEEXAM1\n",
      "DIABEYE1\n",
      "DIABEDU1\n",
      "FEETSORE\n",
      "ARTHEXER\n",
      "ARTHEDU\n",
      "LMTJOIN3\n",
      "ARTHDIS2\n",
      "JOINPAI2\n",
      "LCSFIRST\n",
      "LCSLAST\n",
      "LCSNUMCG\n",
      "LCSCTSC1\n",
      "LCSSCNCR\n",
      "LCSCTWHN\n",
      "HADMAM\n",
      "HOWLONG\n",
      "CERVSCRN\n",
      "CRVCLCNC\n",
      "CRVCLPAP\n",
      "CRVCLHPV\n",
      "HADHYST2\n",
      "PSATEST1\n",
      "PSATIME1\n",
      "PCPSARS2\n",
      "PSASUGS1\n",
      "PCSTALK2\n",
      "HADSIGM4\n",
      "COLNSIGM\n",
      "COLNTES1\n",
      "SIGMTES1\n",
      "LASTSIG4\n",
      "COLNCNCR\n",
      "VIRCOLO1\n",
      "VCLNTES2\n",
      "SMALSTOL\n",
      "STOLTEST\n",
      "STOOLDN2\n",
      "BLDSTFIT\n",
      "SDNATES1\n",
      "CNCRDIFF\n",
      "CNCRAGE\n",
      "CNCRTYP2\n",
      "CSRVTRT3\n",
      "CSRVDOC1\n",
      "CSRVSUM\n",
      "CSRVRTRN\n",
      "CSRVINST\n",
      "CSRVINSR\n",
      "CSRVDEIN\n",
      "CSRVCLIN\n",
      "CSRVPAIN\n",
      "CSRVCTL2\n",
      "INDORTAN\n",
      "NUMBURN3\n",
      "SUNPRTCT\n",
      "WKDAYOUT\n",
      "WKENDOUT\n",
      "CIMEMLO1\n",
      "CDWORRY\n",
      "CDDISCU1\n",
      "CDHOUS1\n",
      "CDSOCIA1\n",
      "CAREGIV1\n",
      "CRGVREL4\n",
      "CRGVLNG1\n",
      "CRGVHRS1\n",
      "CRGVPRB3\n",
      "CRGVALZD\n",
      "CRGVPER1\n",
      "CRGVHOU1\n",
      "CRGVEXPT\n",
      "LASTSMK2\n",
      "STOPSMK2\n",
      "MENTCIGS\n",
      "MENTECIG\n",
      "HEATTBCO\n",
      "FIREARM5\n",
      "GUNLOAD\n",
      "LOADULK2\n",
      "HASYMP1\n",
      "HASYMP2\n",
      "HASYMP3\n",
      "HASYMP4\n",
      "HASYMP5\n",
      "HASYMP6\n",
      "STRSYMP1\n",
      "STRSYMP2\n",
      "STRSYMP3\n",
      "STRSYMP4\n",
      "STRSYMP5\n",
      "STRSYMP6\n",
      "FIRSTAID\n",
      "ASPIRIN\n",
      "BIRTHSEX\n",
      "SOMALE\n",
      "SOFEMALE\n",
      "TRNSGNDR\n",
      "MARIJAN1\n",
      "MARJSMOK\n",
      "MARJEAT\n",
      "MARJVAPE\n",
      "MARJDAB\n",
      "MARJOTHR\n",
      "USEMRJN4\n",
      "ACEDEPRS\n",
      "ACEDRINK\n",
      "ACEDRUGS\n",
      "ACEPRISN\n",
      "ACEDIVRC\n",
      "ACEPUNCH\n",
      "ACEHURT1\n",
      "ACESWEAR\n",
      "ACETOUCH\n",
      "ACETTHEM\n",
      "ACEHVSEX\n",
      "ACEADSAF\n",
      "ACEADNED\n",
      "IMFVPLA4\n",
      "HPVADVC4\n",
      "HPVADSHT\n",
      "TETANUS1\n",
      "COVIDVA1\n",
      "COVACGE1\n",
      "COVIDNU2\n",
      "LSATISFY\n",
      "EMTSUPRT\n",
      "SDLONELY\n",
      "SDHEMPLY\n",
      "FOODSTMP\n",
      "SDHFOOD1\n",
      "SDHBILLS\n",
      "SDHUTILS\n",
      "SDHTRNSP\n",
      "SDHSTRE1\n",
      "RRCLASS3\n",
      "RRCOGNT2\n",
      "RRTREAT\n",
      "RRATWRK2\n",
      "RRHCARE4\n",
      "RRPHYSM2\n",
      "RCSGEND1\n",
      "RCSXBRTH\n",
      "RCSRLTN2\n",
      "CASTHDX2\n",
      "CASTHNO2\n",
      "QSTVER\n",
      "QSTLANG\n",
      "_METSTAT\n",
      "_URBSTAT\n",
      "MSCODE\n",
      "_STSTR\n",
      "_STRWT\n",
      "_RAWRAKE\n",
      "_WT2RAKE\n",
      "_IMPRACE\n",
      "_CHISPNC\n",
      "_CRACE1\n",
      "CAGEG\n",
      "_CLLCPWT\n",
      "_DUALUSE\n",
      "_DUALCOR\n",
      "_LLCPWT2\n",
      "_LLCPWT\n",
      "_RFHLTH\n",
      "_PHYS14D\n",
      "_MENT14D\n",
      "_HLTHPL1\n",
      "_HCVU653\n",
      "_TOTINDA\n",
      "METVL12_\n",
      "METVL22_\n",
      "MAXVO21_\n",
      "FC601_\n",
      "ACTIN13_\n",
      "ACTIN23_\n",
      "PADUR1_\n",
      "PADUR2_\n",
      "PAFREQ1_\n",
      "PAFREQ2_\n",
      "_MINAC12\n",
      "_MINAC22\n",
      "STRFREQ_\n",
      "PAMISS3_\n",
      "PAMIN13_\n",
      "PAMIN23_\n",
      "PA3MIN_\n",
      "PAVIG13_\n",
      "PAVIG23_\n",
      "PA3VIGM_\n",
      "_PACAT3\n",
      "_PAINDX3\n",
      "_PA150R4\n",
      "_PA300R4\n",
      "_PA30023\n",
      "_PASTRNG\n",
      "_PAREC3\n",
      "_PASTAE3\n",
      "_RFHYPE6\n",
      "_CHOLCH3\n",
      "_RFCHOL3\n",
      "_MICHD\n",
      "_LTASTH1\n",
      "_CASTHM1\n",
      "_ASTHMS1\n",
      "_DRDXAR2\n",
      "_MRACE1\n",
      "_HISPANC\n",
      "_RACE\n",
      "_RACEG21\n",
      "_RACEGR3\n",
      "_RACEPRV\n",
      "_SEX\n",
      "_AGEG5YR\n",
      "_AGE65YR\n",
      "_AGE80\n",
      "_AGE_G\n",
      "HTIN4\n",
      "HTM4\n",
      "WTKG3\n",
      "_BMI5\n",
      "_BMI5CAT\n",
      "_RFBMI5\n",
      "_CHLDCNT\n",
      "_EDUCAG\n",
      "_INCOMG1\n",
      "_SMOKER3\n",
      "_RFSMOK3\n",
      "_CURECI2\n",
      "DRNKANY6\n",
      "DROCDY4_\n",
      "_RFBING6\n",
      "_DRNKWK2\n",
      "_RFDRHV8\n",
      "_FLSHOT7\n",
      "_PNEUMO3\n",
      "_AIDTST4\n",
      "_RFSEAT2\n",
      "_RFSEAT3\n",
      "_DRNKDRV\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset without specifying usecols\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display all column names\n",
    "columns_list = df.columns.tolist()\n",
    "\n",
    "# Print all column names one by one to avoid truncation\n",
    "for col in columns_list:\n",
    "    print(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the complete list of relevant columns for analysis\n",
    "columns_of_interest = [\n",
    "    'MENTHLTH', '_AGEG5YR', '_AGE65YR', '_RACEGR3', 'EDUCA', '_EDUCAG',\n",
    "    'INCOME3', '_INCOMG1', 'MARITAL', 'EMPLOY1', '_TOTINDA', 'EXERANY2',\n",
    "    '_RFSMOK3', 'SMOKE100', 'SMOKDAY2', 'DRNK3GE5', 'MAXDRNKS', 'ALCDAY4',\n",
    "    'AVEDRNK3', 'GENHLTH', 'PHYSHLTH', 'POORHLTH', 'DIABETE4', 'CHCSCNC1',\n",
    "    'CHCOCNC1', 'CHCCOPD3', 'FLUSHOT7', 'HIVTST7'\n",
    "]\n",
    "# Load the dataset with only the relevant columns\n",
    "cleaning_df = pd.read_csv(file_path, usecols=columns_of_interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 433323 entries, 0 to 433322\n",
      "Columns: 350 entries, _STATE to _DRNKDRV\n",
      "dtypes: float64(345), int64(5)\n",
      "memory usage: 1.1 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              _STATE         FMONTH         IDATE         IMONTH  \\\n",
      "count  433323.000000  433323.000000  4.333230e+05  433323.000000   \n",
      "mean       30.486898       6.612273  6.809769e+06       6.652947   \n",
      "std        16.670560       3.518848  3.429094e+06       3.428158   \n",
      "min         1.000000       1.000000  1.012024e+06       1.000000   \n",
      "25%        18.000000       3.000000  4.042023e+06       4.000000   \n",
      "50%        29.000000       7.000000  7.072023e+06       7.000000   \n",
      "75%        45.000000      10.000000  1.006202e+07      10.000000   \n",
      "max        78.000000      12.000000  1.231202e+07      12.000000   \n",
      "\n",
      "                IDAY          IYEAR       DISPCODE         SEQNO  \\\n",
      "count  433323.000000  433323.000000  433323.000000  4.333230e+05   \n",
      "mean       15.479848    2023.058411    1117.783963  2.023005e+09   \n",
      "std         8.671355       0.234520      38.237812  4.455869e+03   \n",
      "min         1.000000    2023.000000    1100.000000  2.023000e+09   \n",
      "25%         8.000000    2023.000000    1100.000000  2.023002e+09   \n",
      "50%        15.000000    2023.000000    1100.000000  2.023004e+09   \n",
      "75%        23.000000    2023.000000    1100.000000  2.023008e+09   \n",
      "max        31.000000    2024.000000    1200.000000  2.023026e+09   \n",
      "\n",
      "               _PSU  CTELENM1  ...       DROCDY4_       _RFBING6  \\\n",
      "count  4.333230e+05   88345.0  ...  433323.000000  433323.000000   \n",
      "mean   2.023005e+09       1.0  ...      77.469760       1.739282   \n",
      "std    4.455869e+03       0.0  ...     225.612523       2.123753   \n",
      "min    2.023000e+09       1.0  ...       0.000000       1.000000   \n",
      "25%    2.023002e+09       1.0  ...       0.000000       1.000000   \n",
      "50%    2.023004e+09       1.0  ...       3.000000       1.000000   \n",
      "75%    2.023008e+09       1.0  ...      29.000000       1.000000   \n",
      "max    2.023026e+09       1.0  ...     900.000000       9.000000   \n",
      "\n",
      "            _DRNKWK2       _RFDRHV8       _FLSHOT7       _PNEUMO3  \\\n",
      "count  433323.000000  433323.000000  170823.000000  170823.000000   \n",
      "mean     7826.638676       1.660750       2.138272       2.270057   \n",
      "std     26371.148838       2.113355       2.368834       2.618224   \n",
      "min         0.000000       1.000000       1.000000       1.000000   \n",
      "25%         0.000000       1.000000       1.000000       1.000000   \n",
      "50%        47.000000       1.000000       1.000000       1.000000   \n",
      "75%       400.000000       1.000000       2.000000       2.000000   \n",
      "max     99900.000000       9.000000       9.000000       9.000000   \n",
      "\n",
      "            _AIDTST4       _RFSEAT2       _RFSEAT3       _DRNKDRV  \n",
      "count  403710.000000  433323.000000  433323.000000  433323.000000  \n",
      "mean        2.028681       1.633470       1.698735       5.565327  \n",
      "std         1.686731       2.074538       2.069306       3.515690  \n",
      "min         1.000000       1.000000       1.000000       1.000000  \n",
      "25%         1.000000       1.000000       1.000000       2.000000  \n",
      "50%         2.000000       1.000000       1.000000       9.000000  \n",
      "75%         2.000000       1.000000       1.000000       9.000000  \n",
      "max         9.000000       9.000000       9.000000       9.000000  \n",
      "\n",
      "[8 rows x 350 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as a csv \n",
    "cleaning_df.to_csv('cleaned_brfss_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "picked_features_df = pd.read_csv('cleaned_brfss_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values for features with small amounts of missing data\n",
    "small_missing_features = ['GENHLTH', 'MENTHLTH', 'CHCSCNC1', 'CHCOCNC1', 'CHCCOPD3', 'DIABETE4', 'PHYSHLTH']\n",
    "features_cleaned = picked_features_df.dropna(subset=small_missing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baderrezek/miniconda3/envs/CS418/lib/python3.12/site-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values for features with moderate missing data using median or mode\n",
    "# Use median for numerical columns and mode for categorical ones\n",
    "features_cleaned['SMOKE100'].fillna(features_cleaned['SMOKE100'].mode()[0], inplace=True)\n",
    "features_cleaned['ALCDAY4'].fillna(features_cleaned['ALCDAY4'].median(), inplace=True)\n",
    "features_cleaned['INCOME3'].fillna(features_cleaned['INCOME3'].mode()[0], inplace=True)\n",
    "features_cleaned['AVEDRNK3'].fillna(features_cleaned['AVEDRNK3'].median(), inplace=True)\n",
    "features_cleaned['DRNK3GE5'].fillna(features_cleaned['DRNK3GE5'].median(), inplace=True)\n",
    "features_cleaned['FLUSHOT7'].fillna(features_cleaned['FLUSHOT7'].mode()[0], inplace=True)\n",
    "features_cleaned['HIVTST7'].fillna(features_cleaned['HIVTST7'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'EXERANY2', 'CHCSCNC1',\n",
      "       'CHCOCNC1', 'CHCCOPD3', 'DIABETE4', 'MARITAL', 'EDUCA', 'EMPLOY1',\n",
      "       'INCOME3', 'SMOKE100', 'SMOKDAY2', 'ALCDAY4', 'AVEDRNK3', 'DRNK3GE5',\n",
      "       'MAXDRNKS', 'FLUSHOT7', 'HIVTST7', '_TOTINDA', '_RACEGR3', '_AGEG5YR',\n",
      "       '_AGE65YR', '_EDUCAG', '_INCOMG1', '_RFSMOK3'],\n",
      "      dtype='object')\n",
      "GENHLTH          0\n",
      "PHYSHLTH         0\n",
      "MENTHLTH         0\n",
      "POORHLTH    181149\n",
      "EXERANY2         0\n",
      "CHCSCNC1         0\n",
      "CHCOCNC1         0\n",
      "CHCCOPD3         0\n",
      "DIABETE4         0\n",
      "MARITAL          2\n",
      "EDUCA            4\n",
      "EMPLOY1       2962\n",
      "INCOME3          0\n",
      "SMOKE100         0\n",
      "SMOKDAY2    274675\n",
      "ALCDAY4          0\n",
      "AVEDRNK3         0\n",
      "DRNK3GE5         0\n",
      "MAXDRNKS    222029\n",
      "FLUSHOT7         0\n",
      "HIVTST7          0\n",
      "_TOTINDA         0\n",
      "_RACEGR3        86\n",
      "_AGEG5YR         0\n",
      "_AGE65YR         0\n",
      "_EDUCAG          0\n",
      "_INCOMG1         0\n",
      "_RFSMOK3         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(features_cleaned.columns)\n",
    "\n",
    "# Verify the cleaning\n",
    "print(features_cleaned.isnull().sum())\n",
    "\n",
    "# Save the cleaned dataset if needed\n",
    "features_cleaned.to_csv('cleaned_brfss_handled_missing.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming the Categorical Vars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "\n",
    "cleaned_df = pd.read_csv('cleaned_brfss_handled_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing: 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'EXERANY2', 'CHCSCNC1', 'CHCOCNC1', 'CHCCOPD3', 'DIABETE4', 'MARITAL', 'EDUCA', 'EMPLOY1', 'INCOME3', 'SMOKE100', 'SMOKDAY2', 'ALCDAY4', 'AVEDRNK3', 'DRNK3GE5', 'MAXDRNKS', 'FLUSHOT7', 'HIVTST7', '_TOTINDA', '_RACEGR3', '_AGEG5YR', '_AGE65YR', '_EDUCAG', '_INCOMG1', '_RFSMOK3'\n",
    "\n",
    "# changing GENHLTH values: 1: Excellent, 2: Very good, 3: Good, 4: Fair, 5: Poor, 7: Not sure, 9: Refused, Blank: Missing\n",
    "cleaned_df['GENHLTH'] = cleaned_df['GENHLTH'].replace({1: 'Excellent', 2: 'Very good', 3: 'Good', 4: 'Fair', 5: 'Poor', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "genhlth_order = ['Excellent', 'Very good', 'Good', 'Fair', 'Poor']\n",
    "cleaned_df['GENHLTH'] = pd.Categorical(cleaned_df['GENHLTH'], categories=genhlth_order, ordered=True)\n",
    "\n",
    "# changing MENTHLTH values: 88: None, 77: Not sure, 99: Refused\n",
    "cleaned_df['MENTHLTH'] = cleaned_df['MENTHLTH'].replace({88: 'Not sure', 77: 'Refused', 99: 'Refused'})\n",
    "\n",
    "# changing PHYSHLTH values: 88: None, 77: Not sure, 99: Refused\n",
    "cleaned_df['PHYSHLTH'] = cleaned_df['PHYSHLTH'].replace({88: 'Not sure', 77: 'Refused', 99: 'Refused'})\n",
    "\n",
    "# changing POORHLTH values: 88: None, 77: Not sure, 99: Refused\n",
    "cleaned_df['POORHLTH'] = cleaned_df['POORHLTH'].replace({88: 'Not sure', 77: 'Refused', 99: 'Refused'})\n",
    "\n",
    "# changing EXERANY2 values: 1: Yes, 2: No, 7: Not sure, 9: Refused\n",
    "cleaned_df['EXERANY2'] = cleaned_df['EXERANY2'].replace({1: 'Yes', 2: 'No', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing CHCSCNC1 values: 1: Yes, 2: No, 7: Not sure, 9: Refused\n",
    "cleaned_df['CHCSCNC1'] = cleaned_df['CHCSCNC1'].replace({1: 'Yes', 2: 'No', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing CHCOCNC1 values: 1: Yes, 2: No, 7: Not sure, 9: Refused\n",
    "cleaned_df['CHCOCNC1'] = cleaned_df['CHCOCNC1'].replace({1: 'Yes', 2: 'No', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing CHCCOPD3 values: 1: Yes, 2: No, 7: Not sure, 9: Refused\n",
    "cleaned_df['CHCCOPD3'] = cleaned_df['CHCCOPD3'].replace({1: 'Yes', 2: 'No', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing DIABETE4 values: 1: Yes, 2: Yes, but female told only during pregnancy, 3: No, 4: No, pre-diabetes or borderline diabetes , 7: Not sure, 9: Refused\n",
    "cleaned_df['DIABETE4'] = cleaned_df['DIABETE4'].replace({1: 'Yes', 2: 'Yes, but female told only during pregnancy', 3: 'No', 4: 'No, pre-diabetes or borderline diabetes', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing MARITAL values: 1: Married, 2: Divorced, 3: Widowed, 4: Separated, 5: Never married, 6: A member of an unmarried couple, 9: Refused\n",
    "cleaned_df['MARITAL'] = cleaned_df['MARITAL'].replace({1: 'Married', 2: 'Divorced', 3: 'Widowed', 4: 'Separated', 5: 'Never married', 6: 'A member of an unmarried couple', 9: 'Refused'})\n",
    "\n",
    "# changing EDUCA values: \n",
    "#   1: Never attended school or only kindergarten, \n",
    "#   2: Grades 1 through 8 (Elementary), \n",
    "#   3: Grades 9 through 11 (Some high school), \n",
    "#   4: Grade 12 or GED (High school graduate), \n",
    "#   5: College 1 year to 3 years (Some college or technical school), \n",
    "#   6: College 4 years or more (College graduate), \n",
    "#   9: Refused\n",
    "cleaned_df['EDUCA'] = cleaned_df['EDUCA'].replace({1: 'Never attended school or only kindergarten', 2: 'Grades 1 through 8 (Elementary)', 3: 'Grades 9 through 11 (Some high school)', 4: 'Grade 12 or GED (High school graduate)', 5: 'College 1 year to 3 years (Some college or technical school)', 6: 'College 4 years or more (College graduate)', 9: 'Refused'})\n",
    "\n",
    "educa_order = ['Never attended school or only kindergarten', 'Grades 1 through 8 (Elementary)',\n",
    "               'Grades 9 through 11 (Some high school)', 'Grade 12 or GED (High school graduate)', \n",
    "               'College 1 year to 3 years (Some college or technical school)', \n",
    "               'College 4 years or more (College graduate)']\n",
    "\n",
    "cleaned_df['EDUCA'] = pd.Categorical(cleaned_df['EDUCA'], categories=educa_order, ordered=True)\n",
    "\n",
    "\n",
    "# changing EMPLOY1 values: \n",
    "#   1: Employed for wages, \n",
    "#   2: Self-employed,\n",
    "#   3: Out of work for 1 year or more, \n",
    "#   4: Out of work for less than 1 year, \n",
    "#   5: A homemaker, \n",
    "#   6: A student, \n",
    "#   7: Retired, \n",
    "#   8: Unable to work, \n",
    "#   9: Refused\n",
    "cleaned_df['EMPLOY1'] = cleaned_df['EMPLOY1'].replace({1: 'Employed for wages', 2: 'Self-employed', 3: 'Out of work for 1 year or more', 4: 'Out of work for less than 1 year', 5: 'A homemaker', 6: 'A student', 7: 'Retired', 8: 'Unable to work', 9: 'Refused'})\n",
    "\n",
    "# changing INCOME3 values:\n",
    "#   1: Less than $10,000,\n",
    "#   2: Less than $15,000\n",
    "#   3: Less than $20,000\n",
    "#   4: Less than $25,000\n",
    "#   5: Less than $35,000\n",
    "#   7: Less than $50,000\n",
    "#   8: Less than $75,000\n",
    "#   9: Less than $100,000\n",
    "#   10: Less than $150,000\n",
    "#   11: Less than $200,000\n",
    "#   12: $200,000 or more\n",
    "#   77: Not sure\n",
    "#   99: Refused\n",
    "cleaned_df['INCOME3'] = cleaned_df['INCOME3'].replace({1: 'Less than $10,000', 2: 'Less than $15,000', 3: 'Less than $20,000', 4: 'Less than $25,000', 5: 'Less than $35,000', 7: 'Less than $50,000', 8: 'Less than $75,000', 9: 'Less than $100,000', 10: 'Less than $150,000', 11: 'Less than $200,000', 12: '$200,000 or more', 77: 'Not sure', 99: 'Refused'})\n",
    "\n",
    "income_order = ['Less than $10,000', 'Less than $15,000', 'Less than $20,000', \n",
    "                'Less than $25,000', 'Less than $35,000', 'Less than $50,000', \n",
    "                'Less than $75,000', 'Less than $100,000', 'Less than $150,000', \n",
    "                'Less than $200,000', '$200,000 or more']\n",
    "\n",
    "cleaned_df['INCOME3'] = pd.Categorical(cleaned_df['INCOME3'], categories=income_order, ordered=True)\n",
    "\n",
    "\n",
    "# changing SMOKE100 values: 1: Yes, 2: No, 7: Not sure, 9: Refused\n",
    "cleaned_df['SMOKE100'] = cleaned_df['SMOKE100'].replace({1: 'Yes', 2: 'No', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing SMOKDAY2 values:\n",
    "#   1: Every day,\n",
    "#   2: Some days,\n",
    "#   3: Not at all,\n",
    "#   7: Not sure,\n",
    "#   9: Refused\n",
    "cleaned_df['SMOKDAY2'] = cleaned_df['SMOKDAY2'].replace({1: 'Every day', 2: 'Some days', 3: 'Not at all', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing ALCDAY4 values:\n",
    "#   if 101-199: Number of drinks in past week (calculated by number - 100)\n",
    "#   if 201-299: Number of drinks in past month (calculated by number - 200)\n",
    "#   777: Not sure\n",
    "#   888: No drinks in past week\n",
    "#   999: Refused\n",
    "#   To better calculate the average number of drinks per day, we will convert the values that are in the range 201-299 to the equivalent number of drinks per week by subtracting 100 and then dividing by 4.34524 (average number of weeks in a month). \n",
    "#   We will also convert the values that are in the range 101-199 to the equivalent number of drinks per week by subtrcting 100\n",
    "cleaned_df['ALCDAY4'] = cleaned_df['ALCDAY4'].apply(lambda x: (x - 200) / 4.34524 if x >= 201 and x <= 299 else x - 100 if x >= 101 and x <= 199 else x)\n",
    "\n",
    "# changing AVEDRNK3 values:\n",
    "#   if 1- 76: Number of drinks per day\n",
    "#   77: Not sure\n",
    "#   88: None\n",
    "#   99: Refused\n",
    "cleaned_df['AVEDRNK3'] = cleaned_df['AVEDRNK3'].replace({77: 'Not sure', 88: 'None', 99: 'Refused'})\n",
    "\n",
    "# changing DRNK3GE5 values:\n",
    "#   if 1-76: Number of times in past 30 days drank 5 or more drinks (men) or 4 or more drinks (women)\n",
    "#   77: Not sure\n",
    "#   88: None\n",
    "#   99: Refused\n",
    "cleaned_df['DRNK3GE5'] = cleaned_df['DRNK3GE5'].replace({77: 'Not sure', 88: 'None', 99: 'Refused'})\n",
    "\n",
    "\n",
    "# changing MAXDRNKS values:\n",
    "#   if 1-76: Max num of drinks on any occasion\n",
    "#   77: Not sure\n",
    "#   88: Invalid response\n",
    "#   99: Refused\n",
    "cleaned_df['MAXDRNKS'] = cleaned_df['MAXDRNKS'].replace({77: 'Not sure', 88: 'Invalid response', 99: 'Refused'})\n",
    "\n",
    "# changing FLUSHOT7 values: 1: Yes, 2: No, 7: Not sure, 9: Refused\n",
    "cleaned_df['FLUSHOT7'] = cleaned_df['FLUSHOT7'].replace({1: 'Yes', 2: 'No', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing HIVTST7 values: 1: Yes, 2: No, 7: Not sure, 9: Refused\n",
    "cleaned_df['HIVTST7'] = cleaned_df['HIVTST7'].replace({1: 'Yes', 2: 'No', 7: 'Not sure', 9: 'Refused'})\n",
    "\n",
    "# changing _TOTINDA values: 1: Yes, 2: No, 9: Not sure/Refused/Missing\n",
    "cleaned_df['_TOTINDA'] = cleaned_df['_TOTINDA'].replace({1: 'Yes', 2: 'No', 9: 'Not sure/Refused/Missing'})\n",
    "\n",
    "# changing _RACEGR3 values: \n",
    "#   1: White only, Non-Hispanic, \n",
    "#   2: Black only, Non-Hispanic,\n",
    "#   3: Other race only, Non-Hispanic,\n",
    "#   4: Multiracial, Non-Hispanic,\n",
    "#   5: Hispanic,\n",
    "#   9: Not sure/Refused\n",
    "cleaned_df['_RACEGR3'] = cleaned_df['_RACEGR3'].replace({1: 'White only, Non-Hispanic', 2: 'Black only, Non-Hispanic', 3: 'Other race only, Non-Hispanic', 4: 'Multiracial, Non-Hispanic', 5: 'Hispanic', 9: 'Not sure/Refused'})\n",
    "\n",
    "# changing _AGEG5YR values:\n",
    "#   1: 18-24 years,\n",
    "#   2: 25-29 years,\n",
    "#   3: 30-34 years,\n",
    "#   4: 35-39 years,\n",
    "#   5: 40-44 years,\n",
    "#   6: 45-49 years,\n",
    "#   7: 50-54 years,\n",
    "#   8: 55-59 years,\n",
    "#   9: 60-64 years,\n",
    "#   10: 65-69 years,\n",
    "#   11: 70-74 years,\n",
    "#   12: 75-79 years,\n",
    "#   13: 80 or older\n",
    "#   14: Not sure/Refused/Missing\n",
    "cleaned_df['_AGEG5YR'] = cleaned_df['_AGEG5YR'].replace({1: '18-24 years', 2: '25-29 years', 3: '30-34 years', 4: '35-39 years', 5: '40-44 years', 6: '45-49 years', 7: '50-54 years', 8: '55-59 years', 9: '60-64 years', 10: '65-69 years', 11: '70-74 years', 12: '75-79 years', 13: '80 or older', 14: 'Not sure/Refused/Missing'})\n",
    "\n",
    "age_order = ['18-24 years', '25-29 years', '30-34 years', '35-39 years', '40-44 years',\n",
    "             '45-49 years', '50-54 years', '55-59 years', '60-64 years', '65-69 years',\n",
    "             '70-74 years', '75-79 years', '80 or older']\n",
    "\n",
    "cleaned_df['_AGEG5YR'] = pd.Categorical(cleaned_df['_AGEG5YR'], categories=age_order, ordered=True)\n",
    "\n",
    "# changing _AGE65YR values: 1: Age 18 to 64, 2: Age 65 or older, 9: Not sure/Refused/Missing\n",
    "cleaned_df['_AGE65YR'] = cleaned_df['_AGE65YR'].replace({1: 'Age 18 to 64', 2: 'Age 65 or older', 9: 'Not sure/Refused/Missing'})\n",
    "\n",
    "# changing _EDUCAG values:\n",
    "#   1: Did not graduate High School\n",
    "#   2: Graduated High School\n",
    "#   3: Attended College or Technical School\n",
    "#   4: Graduated from College or Technical School\n",
    "#   9: Not sure/Refused/Missing\n",
    "cleaned_df['_EDUCAG'] = cleaned_df['_EDUCAG'].replace({1: 'Did not graduate High School', 2: 'Graduated High School', 3: 'Attended College or Technical School', 4: 'Graduated from College or Technical School', 9: 'Not sure/Refused/Missing'})\n",
    "\n",
    "# changing _INCOMG1 values:\n",
    "#   1: Less than $15,000\n",
    "#   2: $15,000 - $25,000\n",
    "#   3: $25,000 - $35,000\n",
    "#   4: $35,000 - $50,000\n",
    "#   5: $50,000 - $100,000\n",
    "#   6: $100,000 - $200,000\n",
    "#   7: $200,000 or more\n",
    "#   9: Not sure/Refused/Missing\n",
    "cleaned_df['_INCOMG1'] = cleaned_df['_INCOMG1'].replace({1: 'Less than $15,000', 2: '$15,000 - $25,000', 3: '$25,000 - $35,000', 4: '$35,000 - $50,000', 5: '$50,000 - $100,000', 6: '$100,000 - $200,000', 7: '$200,000 or more', 9: 'Not sure/Refused/Missing'})\n",
    "\n",
    "# changing _RFSMOK3 values:\n",
    "#   1: Not a current smoker\n",
    "#   2: Current smoker\n",
    "#   9: Not sure/Refused/Missing\n",
    "cleaned_df['_RFSMOK3'] = cleaned_df['_RFSMOK3'].replace({1: 'Not a current smoker', 2: 'Current smoker', 9: 'Not sure/Refused/Missing'})\n",
    "\n",
    "rfsmok_order = ['Not a current smoker', 'Current smoker']\n",
    "cleaned_df['_RFSMOK3'] = pd.Categorical(cleaned_df['_RFSMOK3'], categories=rfsmok_order, ordered=True)\n",
    "\n",
    "# Set non-numeric responses to NaN for relevant health columns\n",
    "for col in ['MENTHLTH', 'PHYSHLTH', 'POORHLTH', 'ALCDAY4', 'AVEDRNK3', 'DRNK3GE5', 'MAXDRNKS']:\n",
    "    cleaned_df[col] = pd.to_numeric(cleaned_df[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in GENHLTH: ['Very good', 'Fair', 'Good', 'Poor', 'Excellent', NaN]\n",
      "Categories (5, object): ['Excellent' < 'Very good' < 'Good' < 'Fair' < 'Poor']\n",
      "Unique values in PHYSHLTH: [nan  6.  2.  8.  1.  5.  4. 30. 15. 21. 10. 25. 14.  7. 20.  3. 12. 26.\n",
      "  9. 24. 18. 13. 28. 23. 16. 17. 11. 29. 27. 22. 19.]\n",
      "Unique values in MENTHLTH: [nan  2.  3. 10. 25.  5. 30. 20. 15. 12.  4.  1.  6. 21. 14.  7. 29.  8.\n",
      " 18. 16. 17.  9. 28. 13. 22. 11. 24. 27. 23. 26. 19.]\n",
      "Unique values in POORHLTH: [nan  1. 30. 25.  9.  5. 14.  2.  3. 10. 15.  7.  8. 20.  4. 28.  6. 18.\n",
      " 13. 12. 16. 29. 26. 21. 23. 22. 27. 19. 11. 17. 24.]\n",
      "Unique values in EXERANY2: ['No' 'Yes' nan]\n",
      "Unique values in CHCSCNC1: ['No' 'Yes' nan]\n",
      "Unique values in CHCOCNC1: ['No' 'Yes' nan]\n",
      "Unique values in CHCCOPD3: ['No' 'Yes' nan]\n",
      "Unique values in DIABETE4: ['Yes' 'No' 'Yes, but female told only during pregnancy' nan\n",
      " 'No, pre-diabetes or borderline diabetes']\n",
      "Unique values in MARITAL: ['Married' 'Divorced' 'Widowed' 'A member of an unmarried couple'\n",
      " 'Never married' 'Separated' nan]\n",
      "Unique values in EDUCA: ['College 1 year to 3 years (Some college or te..., 'Grade 12 or GED (High school graduate)', 'College 4 years or more (College graduate)', 'Grades 9 through 11 (Some high school)', 'Grades 1 through 8 (Elementary)', NaN, 'Never attended school or only kindergarten']\n",
      "Categories (6, object): ['Never attended school or only kindergarten' < 'Grades 1 through 8 (Elementary)' < 'Grades 9 through 11 (Some high school)' < 'Grade 12 or GED (High school graduate)' < 'College 1 year to 3 years (Some college or te... < 'College 4 years or more (College graduate)']\n",
      "Unique values in EMPLOY1: ['Retired' 'Unable to work' 'Out of work for less than 1 year'\n",
      " 'Employed for wages' 'A homemaker' 'Self-employed' nan 'A student'\n",
      " 'Out of work for 1 year or more']\n",
      "Unique values in INCOME3: [NaN, 'Less than $15,000', 'Less than $50,000', 'Less than $100,000', 'Less than $20,000', ..., 'Less than $25,000', 'Less than $10,000', 'Less than $75,000', 'Less than $200,000', 'Less than $150,000']\n",
      "Length: 11\n",
      "Categories (11, object): ['Less than $10,000' < 'Less than $15,000' < 'Less than $20,000' < 'Less than $25,000' ... 'Less than $100,000' < 'Less than $150,000' < 'Less than $200,000' < '$200,000 or more']\n",
      "Unique values in SMOKE100: ['No' 'Yes' nan]\n",
      "Unique values in SMOKDAY2: [nan 'Not at all' 'Every day' 'Some days']\n",
      "Unique values in ALCDAY4: [8.88000000e+02 4.60273771e-01 1.15068443e+00 2.00000000e+00\n",
      " 6.90410656e+00 2.30136885e+00 6.90410656e-01 2.30136885e-01\n",
      " 7.00000000e+00 9.20547542e-01 1.00000000e+00 1.38082131e+00\n",
      " 6.00000000e+00 3.45205328e+00 3.00000000e+00 3.22191640e+00\n",
      " 4.00000000e+00 9.99000000e+02 4.60273771e+00 6.67396968e+00\n",
      " 7.77000000e+02 4.83287459e+00 5.75342214e+00 5.00000000e+00\n",
      " 6.44383279e+00 2.76164263e+00 1.61095820e+00 1.84109508e+00\n",
      " 5.52328525e+00 3.68219017e+00 4.37260082e+00 6.21369591e+00\n",
      " 4.14246394e+00 2.07123197e+00 5.98355902e+00 3.91232705e+00\n",
      " 5.29314836e+00 2.53150574e+00 5.06301148e+00 2.99177951e+00]\n",
      "Unique values in AVEDRNK3: [ 2.  1.  4.  5.  6.  3. nan 12. 10.  7. 20. 14.  9. 15.  8. 16. 40. 13.\n",
      " 18. 11. 60. 76. 30. 24. 27. 36. 70. 69. 25. 22. 50. 17. 23. 62. 75. 32.\n",
      " 52. 48. 45. 21. 59. 46. 35. 28. 42. 63. 73. 19. 29. 64.]\n",
      "Unique values in DRNK3GE5: [nan  2. 30.  3. 10.  1.  7.  4.  8.  5.  6. 15. 20. 14. 16. 12.  9. 25.\n",
      " 28. 31. 27. 17. 24. 11. 29. 19. 26. 18. 76. 69. 13. 22. 23. 21. 50. 52.\n",
      " 32. 45. 40. 64. 36. 48. 55. 60. 73. 39.]\n",
      "Unique values in MAXDRNKS: [nan  1.  2.  3.  6.  5.  4.  8. 10. 12.  7. 14. 15. 19. 40. 32.  9. 25.\n",
      " 24. 18. 20. 30. 13. 11. 45. 16. 50. 60. 69. 23. 22. 76. 17. 26. 36. 70.\n",
      " 75. 27. 21. 35. 38. 28. 44. 31. 42. 46. 72. 33. 74. 64. 34. 47. 37. 61.\n",
      " 73. 52. 56. 48. 43. 41. 29. 65.]\n",
      "Unique values in FLUSHOT7: ['No' 'Yes' nan]\n",
      "Unique values in HIVTST7: ['No' 'Yes' nan]\n",
      "Unique values in _TOTINDA: ['No' 'Yes' 'Not sure/Refused/Missing']\n",
      "Unique values in _RACEGR3: ['White only, Non-Hispanic' 'Black only, Non-Hispanic' 'Not sure/Refused'\n",
      " 'Other race only, Non-Hispanic' 'Multiracial, Non-Hispanic' 'Hispanic'\n",
      " nan]\n",
      "Unique values in _AGEG5YR: ['80 or older', '75-79 years', '60-64 years', '55-59 years', '65-69 years', ..., '50-54 years', '25-29 years', '18-24 years', NaN, '30-34 years']\n",
      "Length: 14\n",
      "Categories (13, object): ['18-24 years' < '25-29 years' < '30-34 years' < '35-39 years' ... '65-69 years' < '70-74 years' < '75-79 years' < '80 or older']\n",
      "Unique values in _AGE65YR: ['Age 65 or older' 'Age 18 to 64' 3.0]\n",
      "Unique values in _EDUCAG: ['Attended College or Technical School' 'Graduated High School'\n",
      " 'Graduated from College or Technical School'\n",
      " 'Did not graduate High School' 'Not sure/Refused/Missing']\n",
      "Unique values in _INCOMG1: ['Not sure/Refused/Missing' 'Less than $15,000' '$50,000 - $100,000'\n",
      " '$35,000 - $50,000' '$100,000 - $200,000' '$15,000 - $25,000'\n",
      " '$25,000 - $35,000' '$200,000 or more']\n",
      "Unique values in _RFSMOK3: ['Not a current smoker', 'Current smoker', NaN]\n",
      "Categories (2, object): ['Not a current smoker' < 'Current smoker']\n"
     ]
    }
   ],
   "source": [
    "def replace_with_nan(df, cols, values):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].replace(values, np.nan)\n",
    "    return df\n",
    "\n",
    "# Columns where non-informative responses should be converted to NaN\n",
    "non_informative_values = ['Not sure', 'Refused', 'Don\\'t know/Refused/Missing']\n",
    "\n",
    "# Replace non-informative values with NaN\n",
    "cols_to_replace_nan = ['GENHLTH', 'MENTHLTH', 'PHYSHLTH', 'POORHLTH', 'EXERANY2', 'CHCSCNC1', 'CHCOCNC1', \n",
    "                       'CHCCOPD3', 'DIABETE4', 'MARITAL', 'EDUCA', 'EMPLOY1', 'INCOME3', 'SMOKE100', \n",
    "                       'SMOKDAY2', 'ALCDAY4', 'AVEDRNK3', 'DRNK3GE5', 'MAXDRNKS', 'FLUSHOT7', 'HIVTST7', \n",
    "                       '_TOTINDA', '_RACEGR3', '_AGEG5YR', '_AGE65YR', '_EDUCAG', '_INCOMG1', '_RFSMOK3']\n",
    "\n",
    "cleaned_df = replace_with_nan(cleaned_df, cols_to_replace_nan, non_informative_values)\n",
    "\n",
    "\n",
    "# Set columns to numeric if they contain numeric values and NaNs for non-informative entries\n",
    "numeric_cols = ['MENTHLTH', 'PHYSHLTH', 'POORHLTH', 'ALCDAY4', 'AVEDRNK3', 'DRNK3GE5', 'MAXDRNKS']\n",
    "cleaned_df[numeric_cols] = cleaned_df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Quick check to see unique values across each column after cleaning\n",
    "for col in cleaned_df.columns:\n",
    "    print(f\"Unique values in {col}: {cleaned_df[col].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
